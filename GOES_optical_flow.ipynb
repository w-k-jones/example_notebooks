{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a class to produce optical flow vectors, and perform semi-Lagrangian operations using those vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cv2 as cv\n",
    "from scipy import ndimage as ndi\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# code from https://stackoverflow.com/questions/279237/import-a-module-from-a-relative-path?lq=1#comment15918105_6098238 to load a realitive folde from a notebook\n",
    "# realpath() will make your script run, even if you symlink it :)\n",
    "cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile( inspect.currentframe() ))[0]))\n",
    "if cmd_folder not in sys.path:\n",
    "    sys.path.insert(0, cmd_folder)\n",
    "\n",
    "from utils import io, abi\n",
    "from utils.flow import Flow\n",
    "from utils import legacy_flow as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_data_path = './data/GOES16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/jonesw/Downloads/dcc-detect-4e11a4adbc07.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2018,6,19,16)\n",
    "days = timedelta(days=0.33)\n",
    "dates = pd.date_range(start_date, start_date+days, freq='H', closed='left').to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_files = list(sum([sorted(io.find_abi_files(date, satellite=16, product='MCMIP', view='C', mode=3, \n",
    "                                        save_dir=goes_data_path, \n",
    "                                        replicate_path=True, check_download=True, \n",
    "                                        n_attempts=1, download_missing=True))\n",
    "                  for date in dates],[]))\n",
    "             \n",
    "\n",
    "abi_files = {io.get_goes_date(i):i for i in abi_files}\n",
    "abi_dates = list(abi_files.keys())\n",
    "len(abi_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [(abi_dates[1]-abi_dates[0]).total_seconds()/60] \\\n",
    "     + [(abi_dates[i+2]-abi_dates[i]).total_seconds()/120 \\\n",
    "        for i in range(len(abi_files)-2)] \\\n",
    "     + [(abi_dates[-1]-abi_dates[-2]).total_seconds()/60]\n",
    "dt = np.array(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some multichannel data\n",
    "ds_slice = {'x':slice(1300,1550), 'y':slice(650,900)}\n",
    "# Load a stack of goes datasets using xarray. Select a region over Northern Florida. (full file size in 1500x2500 pixels)\n",
    "goes_ds = xr.open_mfdataset(abi_files.values(), concat_dim='t', combine='nested').isel(ds_slice)\n",
    "wvd = goes_ds.CMI_C08 - goes_ds.CMI_C10\n",
    "bt = goes_ds.CMI_C13\n",
    "swd = goes_ds.CMI_C13 - goes_ds.CMI_C15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_kwargs = {'pyr_scale':0.5, 'levels':6, 'winsize':32, 'iterations':4, \n",
    "               'poly_n':5, 'poly_sigma':1., 'flags':cv.OPTFLOW_FARNEBACK_GAUSSIAN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow(bt, flow_kwargs=flow_kwargs, smoothing_passes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow.flow_for[i,...,0],vmin=-5,vmax=5, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.title('x flow')\n",
    "plt.figure()\n",
    "plt.imshow(flow.flow_for[i,...,1],vmin=-5,vmax=5, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.title('y flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvd_diff = flow.convolve(flow.diff(wvd)/dt[:,np.newaxis,np.newaxis], func=lambda x:np.nanmean(x,0))\n",
    "bt_diff = flow.convolve(flow.diff(bt)/dt[:,np.newaxis,np.newaxis], func=lambda x:np.nanmean(x,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120, figsize=(8,4))\n",
    "plt.imshow(bt[i], cmap='gist_yarg', vmin=180, vmax=320)\n",
    "plt.colorbar()\n",
    "plt.contour(wvd_diff[i], np.linspace(0.05,0.5,10))\n",
    "plt.colorbar()\n",
    "plt.contour(-bt_diff[i], np.linspace(0.05,0.5,10), cmap='inferno')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wvd[i])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = flow.sobel(np.maximum(np.minimum(wvd,-5),-15), direction='uphill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges[i], vmin=0, vmax=50)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wvd_diff[i]>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_flow = lf.Flow_Func(flow.flow_for[...,0], flow.flow_back[...,0], \n",
    "                      flow.flow_for[...,1], flow.flow_back[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = wvd_diff>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ndi.binary_erosion((wvd<=-15).data.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed = lf.flow_network_watershed(edges, markers, l_flow, mask=mask, \n",
    "                                      structure=ndi.generate_binary_structure(3,1),\n",
    "                                      debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges[i],vmin=0, vmax=50)\n",
    "plt.contour(watershed[i], [0.5], colors=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(swd[i])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wvd[i]-swd[i]+wvd_diff[i]*5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_field = wvd-swd+wvd_diff*5\n",
    "inner_edges = flow.sobel(np.maximum(np.minimum(inner_field,-5),-15), direction='uphill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inner_edges[i], vmin=0, vmax=50)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_watershed = lf.flow_network_watershed(inner_edges, markers, l_flow, mask=mask, \n",
    "                                            structure=ndi.generate_binary_structure(3,1),\n",
    "                                            debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inner_edges[i],vmin=0, vmax=50)\n",
    "plt.contour(inner_watershed[i], [0.5], colors=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wvd[i]+swd[i])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_field = wvd+swd\n",
    "outer_edges = flow.sobel(np.maximum(np.minimum(outer_field,-2.5),-7.5), direction='uphill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(outer_edges[i], vmin=0, vmax=50)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_watershed = lf.flow_network_watershed(outer_edges, markers, l_flow, mask=mask, \n",
    "                                            structure=ndi.generate_binary_structure(3,1),\n",
    "                                            debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(outer_edges[i],vmin=0, vmax=50)\n",
    "plt.contour(outer_watershed[i], [0.5], colors=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_watershed = np.maximum(inner_watershed, outer_watershed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_labels = lf.flow_label(outer_watershed, l_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = flow_label(watershed, l_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(96):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(inner_edges[i],vmin=0, vmax=50)\n",
    "    ax[0].contour(inner_watershed[i], [0.5], colors=['red'])\n",
    "    ax[1].imshow(outer_edges[i],vmin=0, vmax=50)\n",
    "    ax[1].contour(outer_watershed[i], [0.5], colors=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.Dataset({\n",
    "                      'inner_watershed':(('t','y','x'), inner_watershed),\n",
    "                      'inner_labels':(('t','y','x'), inner_labels),\n",
    "                      'outer_watershed':(('t','y','x'), outer_watershed),\n",
    "                      'outer_labels':(('t','y','x'), outer_labels),\n",
    "                      'wvd_diff':(('t','y','x'), wvd_diff),\n",
    "                      'x_flow_for':(('t','y','x'), flow.flow_for[...,0]),\n",
    "                      'x_flow_back':(('t','y','x'), flow.flow_back[...,0]),\n",
    "                      'y_flow_for':(('t','y','x'), flow.flow_for[...,1]),\n",
    "                      'y_flow_back':(('t','y','x'), flow.flow_back[...,1]),\n",
    "                      },\n",
    "                     goes_ds.CMI_C13.coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.Dataset({\n",
    "                      'inner_watershed':(('t','y','x'), inner_watershed),\n",
    "                      'inner_labels':(('t','y','x'), inner_labels),\n",
    "                      'outer_watershed':(('t','y','x'), outer_watershed),\n",
    "                      'outer_labels':(('t','y','x'), outer_labels),\n",
    "                      'wvd_diff':(('t','y','x'), wvd_diff),\n",
    "                      'x_flow_for':(('t','y','x'), l_flow.flow_x_for),\n",
    "                      'x_flow_back':(('t','y','x'), l_flow.flow_x_back),\n",
    "                      'y_flow_for':(('t','y','x'), l_flow.flow_y_for),\n",
    "                      'y_flow_back':(('t','y','x'), l_flow.flow_y_back),\n",
    "                      },\n",
    "                     goes_ds.CMI_C13.coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './test_watershed2.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.to_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvd_diff = dataset.wvd_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_watershed = dataset.inner_watershed.data\n",
    "outer_watershed = dataset.outer_watershed.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_flow = lf.Flow_Func(dataset.x_flow_for.data, dataset.x_flow_back.data, \n",
    "                      dataset.y_flow_for.data, dataset.y_flow_back.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_watershed = np.fmax(inner_watershed, outer_watershed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = ndi.generate_binary_structure(3,1)\n",
    "struct[0] = 0\n",
    "struct[-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_watershed = ndi.binary_closing(\n",
    "    ndi.binary_opening(inner_watershed, structure=struct),\n",
    "    structure=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_watershed = ndi.binary_closing(\n",
    "    ndi.binary_opening(outer_watershed, structure=struct),\n",
    "    structure=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_labels = lf.flow_label(inner_watershed, l_flow)\n",
    "outer_labels = lf.flow_label(outer_watershed, l_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(outer_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 36\n",
    "img = plt.imshow(abi.get_abi_rgb(goes_ds.isel({'t':i})))\n",
    "c1 = plt.contour(inner_watershed[0], [0.5], colors=['red'])\n",
    "for coll in c1.collections:\n",
    "    coll.remove()\n",
    "c1 = plt.contour(inner_watershed[i], [0.5], colors=['red'])\n",
    "c2 = plt.contour(outer_watershed[i], [0.5], colors=['blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proj = ccrs.Geostationary(satellite_height=goes_ds.goes_imager_projection.perspective_point_height,\n",
    "                              central_longitude=goes_ds.goes_imager_projection.longitude_of_projection_origin,\n",
    "                              sweep_axis=goes_ds.goes_imager_projection.sweep_angle_axis)\n",
    "h = goes_ds.goes_imager_projection.perspective_point_height\n",
    "img_extent=(goes_ds.x[0]*h, goes_ds.x[-1]*h, goes_ds.y[-1]*h, goes_ds.y[0]*h)\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = plt.subplot(1,1,1,projection=img_proj)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "\n",
    "i = 0\n",
    "img = ax.imshow(abi.get_abi_rgb(goes_ds.isel({'t':i})), \n",
    "                extent=img_extent)\n",
    "c1 = [ax.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "c2 = [ax.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "\n",
    "def init():\n",
    "    return img, c1, c2\n",
    "\n",
    "def animate(i):\n",
    "    img.set_data(abi.get_abi_rgb(goes_ds.isel({'t':i})))\n",
    "    for coll in c1[0].collections:\n",
    "        coll.remove()\n",
    "    c1[0] = ax.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    for coll in c2[0].collections:\n",
    "        coll.remove()\n",
    "    c2[0] = ax.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=96, \n",
    "                               interval=50, blit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save('./dcc_test.mp4', bitrate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_labels = flow_label(inner_watershed, l_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=12\n",
    "plt.imshow(label2rgb(inner_labels[i], \n",
    "                     image=abi.get_abi_rgb(goes_ds.isel({'t':i})),\n",
    "                     bg_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_rgb = abi.get_abi_rgb(goes_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_rgb.reshape(-1,250,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_abi = label2rgb(inner_labels.reshape(-1,250),\n",
    "                         image=abi_rgb.reshape(-1,250,3),\n",
    "                         bg_label=0).reshape(abi_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(labelled_abi[12])\n",
    "plt.figure()\n",
    "plt.imshow(labelled_abi[24])\n",
    "plt.figure()\n",
    "plt.imshow(labelled_abi[36])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proj = ccrs.Geostationary(satellite_height=goes_ds.goes_imager_projection.perspective_point_height,\n",
    "                              central_longitude=goes_ds.goes_imager_projection.longitude_of_projection_origin,\n",
    "                              sweep_axis=goes_ds.goes_imager_projection.sweep_angle_axis)\n",
    "h = goes_ds.goes_imager_projection.perspective_point_height\n",
    "img_extent=(goes_ds.x[0]*h, goes_ds.x[-1]*h, goes_ds.y[-1]*h, goes_ds.y[0]*h)\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = plt.subplot(1,1,1,projection=img_proj)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "\n",
    "i = 0\n",
    "img = ax.imshow(labelled_abi[i], \n",
    "                extent=img_extent)\n",
    "def init():\n",
    "    return img\n",
    "\n",
    "def animate(i):\n",
    "    img.set_data(labelled_abi[i])\n",
    "    return img\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=96, \n",
    "                               interval=50, blit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, display\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, display\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, display\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save('./dcc_colour_test.mp4', bitrate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(inner_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid_files = ['./data/regrid/old/regrid_%s.nc' % (date.strftime('%Y%m%d_%H0000')) for date in dates]\n",
    "print(regrid_files)\n",
    "grid_ds = xr.open_mfdataset(regrid_files, concat_dim='t', combine='nested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proj = ccrs.Geostationary(satellite_height=goes_ds.goes_imager_projection.perspective_point_height,\n",
    "                              central_longitude=goes_ds.goes_imager_projection.longitude_of_projection_origin,\n",
    "                              sweep_axis=goes_ds.goes_imager_projection.sweep_angle_axis)\n",
    "h = goes_ds.goes_imager_projection.perspective_point_height\n",
    "img_extent=(goes_ds.x[0]*h, goes_ds.x[-1]*h, goes_ds.y[-1]*h, goes_ds.y[0]*h)\n",
    "fig = plt.figure(dpi=150)\n",
    "ax1 = plt.subplot(1,2,1,projection=img_proj)\n",
    "ax1.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax2 = plt.subplot(1,2,2,projection=img_proj)\n",
    "ax2.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "\n",
    "i = 0\n",
    "img1 = ax1.imshow(grid_ds.glm_freq[i], vmin=0, vmax=5, \n",
    "                extent=img_extent)\n",
    "c11 = [ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "c21 = [ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "\n",
    "img2 = ax2.imshow(grid_ds.radar_ref[i], vmin=0, vmax=40, \n",
    "                extent=img_extent)\n",
    "c12 = [ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "c22 = [ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "\n",
    "\n",
    "def init():\n",
    "    return img1, c11, c21, img2, c12, c22\n",
    "\n",
    "def animate(i):\n",
    "    img1.set_data(grid_ds.glm_freq[i])\n",
    "    img2.set_data(grid_ds.radar_ref[i])\n",
    "    for coll in c11[0].collections:\n",
    "        coll.remove()\n",
    "    c11[0] = ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    for coll in c21[0].collections:\n",
    "        coll.remove()\n",
    "    c21[0] = ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "    for coll in c12[0].collections:\n",
    "        coll.remove()\n",
    "    c12[0] = ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    for coll in c22[0].collections:\n",
    "        coll.remove()\n",
    "    c22[0] = ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "    return img1, c11, c21, img2, c12, c22\n",
    "    \n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=96, \n",
    "                               interval=50, blit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proj = ccrs.Geostationary(satellite_height=goes_ds.goes_imager_projection.perspective_point_height,\n",
    "                              central_longitude=goes_ds.goes_imager_projection.longitude_of_projection_origin,\n",
    "                              sweep_axis=goes_ds.goes_imager_projection.sweep_angle_axis)\n",
    "h = goes_ds.goes_imager_projection.perspective_point_height\n",
    "img_extent=(goes_ds.x[0]*h, goes_ds.x[-1]*h, goes_ds.y[-1]*h, goes_ds.y[0]*h)\n",
    "fig = plt.figure(dpi=150, figsize=(6,6))\n",
    "ax1 = plt.subplot(2,2,1,projection=img_proj)\n",
    "ax1.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax1.set_title('ABI \"Truecolor\" RGB')\n",
    "ax2 = plt.subplot(2,2,2,projection=img_proj)\n",
    "ax2.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax2.set_title('ABI \"Deep cloud\" RGB')\n",
    "ax3 = plt.subplot(2,2,3,projection=img_proj)\n",
    "ax3.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax3.set_title('GLM Flash Frequency')\n",
    "ax4 = plt.subplot(2,2,4,projection=img_proj)\n",
    "ax4.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax4.set_title('NEXRAD Radar Reflectivity')\n",
    "\n",
    "i = 0\n",
    "img1 = ax1.imshow(abi.get_abi_rgb(goes_ds.isel({'t':i})), \n",
    "                extent=img_extent)\n",
    "c21 = [ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "c11 = [ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "\n",
    "img2 = ax2.imshow(abi.get_abi_deep_cloud_rgb(goes_ds.isel({'t':i})), \n",
    "                extent=img_extent)\n",
    "c22 = [ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['black'])]\n",
    "c12 = [ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "\n",
    "img3 = ax3.imshow(grid_ds.glm_freq[i], vmin=0, vmax=5, \n",
    "                extent=img_extent)\n",
    "c23 = [ax3.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "c13 = [ax3.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "\n",
    "img4 = ax4.imshow(grid_ds.radar_ref[i], vmin=0, vmax=40, \n",
    "                extent=img_extent)\n",
    "c24 = [ax4.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])]\n",
    "c14 = [ax4.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])]\n",
    "\n",
    "\n",
    "def init():\n",
    "    return img1, c11, c21, img2, c12, c22, img3, c13, c23, img4, c14, c24\n",
    "\n",
    "def animate(i):\n",
    "    img1.set_data(abi.get_abi_rgb(goes_ds.isel({'t':i})))\n",
    "    img2.set_data(abi.get_abi_deep_cloud_rgb(goes_ds.isel({'t':i})))\n",
    "    img3.set_data(grid_ds.glm_freq[i])\n",
    "    img4.set_data(grid_ds.radar_ref[i])\n",
    "    \n",
    "    for coll in c21[0].collections:\n",
    "        coll.remove()\n",
    "    c21[0] = ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "    for coll in c11[0].collections:\n",
    "        coll.remove()\n",
    "    c11[0] = ax1.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    \n",
    "    for coll in c22[0].collections:\n",
    "        coll.remove()\n",
    "    c22[0] = ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['black'])\n",
    "    for coll in c12[0].collections:\n",
    "        coll.remove()\n",
    "    c12[0] = ax2.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    \n",
    "    for coll in c23[0].collections:\n",
    "        coll.remove()\n",
    "    c23[0] = ax3.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "    for coll in c13[0].collections:\n",
    "        coll.remove()\n",
    "    c13[0] = ax3.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    \n",
    "    for coll in c24[0].collections:\n",
    "        coll.remove()\n",
    "    c24[0] = ax4.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                outer_watershed[i], [0.5], colors=['blue'])\n",
    "    for coll in c14[0].collections:\n",
    "        coll.remove()\n",
    "    c14[0] = ax4.contour(*np.meshgrid(goes_ds.x*h, goes_ds.y*h), \n",
    "                inner_watershed[i], [0.5], colors=['red'])\n",
    "    \n",
    "    return img1, c11, c21, img2, c12, c22, img3, c13, c23, img4, c14, c24\n",
    "    \n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=96, \n",
    "                               interval=50, blit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, display\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save('./dcc_multi_test.mp4', bitrate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.legacy_flow import flow_convolve_nearest\n",
    "\n",
    "def flow_label(data, flow, structure=ndi.generate_binary_structure(3,1)):\n",
    "    \"\"\"\n",
    "    Labels separate regions in a Lagrangian aware manner using a pre-generated\n",
    "    flow field. Works in a similar manner to scipy.ndimage.label. By default\n",
    "    uses square connectivity\n",
    "    \"\"\"\n",
    "#     Get labels for each time step\n",
    "    t_labels = ndi.label(data, structure=structure * np.array([0,1,0])[:,np.newaxis,np.newaxis])[0].astype(float)\n",
    "\n",
    "    bin_edges = np.cumsum(np.bincount(t_labels.astype(int).ravel()))\n",
    "    args = np.argsort(t_labels.ravel())\n",
    "\n",
    "    t_labels[t_labels==0] = np.nan\n",
    "    # Now get previous labels (lagrangian)\n",
    "    if np.any(structure * np.array([1,0,0])[:,np.newaxis,np.newaxis]):\n",
    "        p_labels = flow_convolve_nearest(t_labels, flow,\n",
    "                                         structure=structure * np.array([1,0,0])[:,np.newaxis,np.newaxis],\n",
    "                                         function=np.nanmin)\n",
    "    #     Map each label to its smallest overlapping label at the previous time step\n",
    "        p_label_map = {i:int(np.nanmin(p_labels.ravel()[args[bin_edges[i-1]:bin_edges[i]]])) \\\n",
    "                   if bin_edges[i-1] < bin_edges[i] \\\n",
    "                       and np.any(np.isfinite(p_labels.ravel()[args[bin_edges[i-1]:bin_edges[i]]])) \\\n",
    "                   else i \\\n",
    "                   for i in range(1, len(bin_edges)) \\\n",
    "                   }\n",
    "    #     Converge to lowest value label\n",
    "        for k in p_label_map:\n",
    "            while p_label_map[k] != p_label_map[p_label_map[k]]:\n",
    "                p_label_map[k] = p_label_map[p_label_map[k]]\n",
    "    #     Check all labels have converged\n",
    "        for k in p_label_map:\n",
    "            assert p_label_map[k] == p_label_map[p_label_map[k]]\n",
    "    #     Relabel\n",
    "        for k in p_label_map:\n",
    "            if p_label_map[k] != k and bin_edges[k-1] < bin_edges[k]:\n",
    "                t_labels.ravel()[args[bin_edges[k-1]:bin_edges[k]]] = p_label_map[k]\n",
    "    # Now get labels for the next step\n",
    "    if np.any(structure * np.array([0,0,1])[:,np.newaxis,np.newaxis]):\n",
    "        n_labels = flow_convolve_nearest(t_labels, flow,\n",
    "                                         structure=structure * np.array([0,0,1])[:,np.newaxis,np.newaxis],\n",
    "                                         function=np.nanmin)\n",
    "    # Set matching labels to NaN to avoid repeating values\n",
    "        n_labels[n_labels==t_labels] = np.nan\n",
    "        # New bins\n",
    "        bins = np.bincount(np.fmax(t_labels.ravel(),0).astype(int))\n",
    "        bin_edges = np.cumsum(bins)\n",
    "        args = np.argsort(np.fmax(t_labels.ravel(),0).astype(int))\n",
    "    #     map each label to the smallest overlapping label at the next time step\n",
    "        n_label_map = {i:int(np.nanmin(n_labels.ravel()[args[bin_edges[i-1]:bin_edges[i]]])) \\\n",
    "                   if bin_edges[i-1] < bin_edges[i] \\\n",
    "                       and np.any(np.isfinite(n_labels.ravel()[args[bin_edges[i-1]:bin_edges[i]]])) \\\n",
    "                   else i \\\n",
    "                   for i in range(1, len(bin_edges)) \\\n",
    "                   }\n",
    "    # converge\n",
    "        for k in sorted(list(n_label_map.keys()))[::-1]:\n",
    "            prev_labels = []\n",
    "            while n_label_map[k] != n_label_map[n_label_map[k]]:\n",
    "                prev_labels.append(n_label_map[k])\n",
    "                if n_label_map[n_label_map[k]] in prev_labels:\n",
    "                    n_label_map[k] = max(prev_labels[prev_labels.index(n_label_map[n_label_map[k]]):])\n",
    "                    break\n",
    "                n_label_map[k] = n_label_map[n_label_map[k]]\n",
    "                \n",
    "    #     Check convergence\n",
    "        for k in n_label_map:\n",
    "            assert n_label_map[k] == n_label_map[n_label_map[k]]\n",
    "    #       Now relabel again\n",
    "        for k in n_label_map:\n",
    "            if n_label_map[k] != k and bin_edges[k-1] < bin_edges[k]:\n",
    "                t_labels.ravel()[args[bin_edges[k-1]:bin_edges[k]]] = n_label_map[k]\n",
    "# New bins\n",
    "    bins = np.bincount(np.fmax(t_labels.ravel(),0).astype(int))\n",
    "    bin_edges = np.cumsum(bins)\n",
    "    args = np.argsort(np.fmax(t_labels.ravel(),0).astype(int))\n",
    "#     relabel with consecutive integer values\n",
    "    for i, label in enumerate(np.unique(t_labels[np.isfinite(t_labels)]).astype(int)):\n",
    "        if bin_edges[label-1] < bin_edges[label]:\n",
    "            t_labels.ravel()[args[bin_edges[label-1]:bin_edges[label]]] = i+1\n",
    "    t_labels = np.fmax(t_labels,0).astype(int)\n",
    "    return t_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min([1,2,3][[1,2,3].index(3):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_watershed = flow_label(watershed, l_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labelled_watershed[84])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_convolve(self, conv_data, arg_data, func='argmin',\n",
    "                    structure=ndi.generate_binary_structure(3,1),\n",
    "                    method='nearest',\n",
    "                    dtype=float):\n",
    "    if func == 'argmin':\n",
    "        func = lambda x:np.nanargmin(x, 0)\n",
    "    elif func == 'argmax':\n",
    "        func = lambda x:np.nanargmax(x, 0)\n",
    "    \n",
    "    assert structure.shape == (3,3,3), \"Structure input must be a 3x3x3 array\"\n",
    "    assert conv_data.shape == self.shape, \"Data input must have the same shape as the Flow object\"\n",
    "    assert arg_data.shape == self.shape\n",
    "    \n",
    "    n_structure = np.count_nonzero(structure)\n",
    "    wh_layer = np.nonzero(structure)\n",
    "    struct_factor = structure[np.nonzero(structure)]\n",
    "    \n",
    "    out_array = np.full(self.shape, np.nan, dtype=dtype)\n",
    "    img_step = -1\n",
    "    \n",
    "    for step in range(self.shape[0]):\n",
    "#       Construct temporary array for the data from this time step\n",
    "        conv_temp = np.full((n_structure,)+self.shape[1:], np.nan)\n",
    "        arg_temp = np.full((n_structure,)+self.shape[1:], np.nan)\n",
    "\n",
    "#       Now loop through elements of structure\n",
    "        for i in range(n_structure):\n",
    "#           For backward steps:\n",
    "            if wh_layer[0][i]==0:\n",
    "                if step > 0:\n",
    "                    if img_step != step-1:\n",
    "                        if hasattr(arg_data, 'compute'):\n",
    "                            arg = arg_data[step-1].compute().data\n",
    "                        else:\n",
    "                            arg = arg_data[step-1]\n",
    "                        if hasattr(conv_data, 'compute'):\n",
    "                            conv = conv_data[step-1].compute().data\n",
    "                        else:\n",
    "                            conv = conv_data[step-1]\n",
    "                        img_step = step-1\n",
    "                    \n",
    "                    arg_temp[i] = self._warp_flow_step(arg, step, \n",
    "                                                       method=method, \n",
    "                                                       direction='backward', \n",
    "                                                       offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                  * struct_factor[i]\n",
    "                    conv_temp[i] = self._warp_flow_step(conv, step, \n",
    "                                                        method=method, \n",
    "                                                        direction='backward', \n",
    "                                                        offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                   * struct_factor[i]\n",
    "#           For forward steps:\n",
    "            elif wh_layer[0][i]==2:\n",
    "                if step < self.shape[0]-1:\n",
    "                    if img_step != step+1:\n",
    "                        if hasattr(arg_data, 'compute'):\n",
    "                            arg = arg_data[step+1].compute().data\n",
    "                        else:\n",
    "                            arg = arg_data[step+1]\n",
    "                        if hasattr(conv_data, 'compute'):\n",
    "                            conv = conv_data[step+1].compute().data\n",
    "                        else:\n",
    "                            conv = conv_data[step+1]\n",
    "                        img_step = step+1\n",
    "                    \n",
    "                    arg_temp[i] = self._warp_flow_step(arg, step, \n",
    "                                                       method=method, \n",
    "                                                       direction='forward', \n",
    "                                                       offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                  * struct_factor[i]\n",
    "                    conv_temp[i] = self._warp_flow_step(conv, step, \n",
    "                                                        method=method, \n",
    "                                                        direction='forward', \n",
    "                                                        offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                   * struct_factor[i]\n",
    "#           For same time step:\n",
    "            else:\n",
    "                if img_step != step:\n",
    "                    if hasattr(arg_data, 'compute'):\n",
    "                        arg = arg_data[step].compute().data\n",
    "                    else:\n",
    "                        arg = arg_data[step]\n",
    "                    if hasattr(conv_data, 'compute'):\n",
    "                        conv = conv_data[step].compute().data\n",
    "                    else:\n",
    "                        conv = conv_data[step]\n",
    "                    img_step = step\n",
    "                    \n",
    "                if wh_layer[1][i]==1 and wh_layer[2][i]==1:\n",
    "                    arg_temp[i] = arg * struct_factor[i]\n",
    "                    conv_temp[i] = conv * struct_factor[i]\n",
    "                else:\n",
    "                    arg_temp[i,\n",
    "                             (1 if wh_layer[2][i]==0 else 0):(-1 if wh_layer[2][i]==2 else None), \n",
    "                             (1 if wh_layer[1][i]==0 else 0):(-1 if wh_layer[1][i]==2 else None)] \\\n",
    "                            = arg[(1 if wh_layer[2][i]==2 else 0):(-1 if wh_layer[2][i]==0 else None), \n",
    "                                  (1 if wh_layer[1][i]==2 else 0):(-1 if wh_layer[1][i]==0 else None)] \\\n",
    "                              * struct_factor[i]\n",
    "                    conv_temp[i,\n",
    "                              (1 if wh_layer[2][i]==0 else 0):(-1 if wh_layer[2][i]==2 else None), \n",
    "                              (1 if wh_layer[1][i]==0 else 0):(-1 if wh_layer[1][i]==2 else None)] \\\n",
    "                              = conv[(1 if wh_layer[2][i]==2 else 0):(-1 if wh_layer[2][i]==0 else None), \n",
    "                                     (1 if wh_layer[1][i]==2 else 0):(-1 if wh_layer[1][i]==0 else None)] \\\n",
    "                                * struct_factor[i]\n",
    "\n",
    "        inds = np.maximum(np.minimum(func(arg_temp), n_structure), 0)\n",
    "        out_array[step] = np.take_along_axis(conv_temp, np.expand_dims(inds, 0), 0).squeeze()\n",
    "    return out_array\n",
    "\n",
    "flow.arg_convolve = arg_convolve.__get__(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_neighbour_fill_field(self, field_data, fill_data,\n",
    "                              structure=ndi.generate_binary_structure(3,1),\n",
    "                              func='argmin', method='nearest',\n",
    "                              dtype=float):\n",
    "    \"\"\"\n",
    "    Find the minimum value of the convolved field at each point where the \n",
    "    convolved location does not have the same fill value as the origin point\n",
    "    \"\"\"\n",
    "    if func == 'argmin':\n",
    "        func = lambda x:np.nanargmin(x, 0)\n",
    "    elif func == 'argmax':\n",
    "        func = lambda x:np.nanargmax(x, 0)\n",
    "    \n",
    "    assert structure.shape == (3,3,3), \"Structure input must be a 3x3x3 array\"\n",
    "#   Set central value of structure to 0 as this will always have the same fill value\n",
    "    structure = structure.copy()\n",
    "    structure[1,1,1] = 0\n",
    "    \n",
    "    assert field_data.shape == self.shape, \"Field data input must have the same shape as the Flow object\"\n",
    "    assert fill_data.shape == self.shape, \"Fill data input must have the same shape as the Flow object\"\n",
    "    \n",
    "    n_structure = np.count_nonzero(structure)\n",
    "    wh_layer = np.nonzero(structure)\n",
    "    struct_factor = structure[np.nonzero(structure)]\n",
    "    \n",
    "#   Pre-allocate output arrays\n",
    "    out_field = np.full(self.shape, np.inf, dtype=field_data.dtype)\n",
    "    out_fill = np.full(self.shape, 0, dtype=fill_data.dtype)\n",
    "#   Set initial image step for data loading\n",
    "    img_step = -1\n",
    "    \n",
    "    for step in range(self.shape[0]):\n",
    "#       Construct temporary array for the data from each time step\n",
    "        field_temp = np.full((n_structure,)+self.shape[1:], np.inf, dtype=field_data.dtype)\n",
    "        fill_temp = np.full((n_structure,)+self.shape[1:], 0, dtype=fill_data.dtype)\n",
    "\n",
    "#       Now loop through elements of structure\n",
    "        for i in range(n_structure):\n",
    "#           For backward steps:\n",
    "            if wh_layer[0][i]==0:\n",
    "                if step > 0:\n",
    "                    if img_step != step-1:\n",
    "                        if hasattr(fill_data, 'compute'):\n",
    "                            fill = fill_data[step-1].compute().data\n",
    "                        else:\n",
    "                            fill = fill_data[step-1]\n",
    "                        if hasattr(field_data, 'compute'):\n",
    "                            field = field_data[step-1].compute().data\n",
    "                        else:\n",
    "                            field = field_data[step-1]\n",
    "                        img_step = step-1\n",
    "                    \n",
    "                    fill_temp[i] = self._warp_flow_step(fill, step, \n",
    "                                                        method=method, \n",
    "                                                        direction='backward', \n",
    "                                                        offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                  * struct_factor[i]\n",
    "                    field_temp[i] = self._warp_flow_step(field, step, \n",
    "                                                         method=method, \n",
    "                                                         direction='backward', \n",
    "                                                         offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                   * struct_factor[i]\n",
    "                    wh = fill_temp[i]<0\n",
    "                    field_temp[i][wh] = np.inf\n",
    "#           For forward steps:\n",
    "            elif wh_layer[0][i]==2:\n",
    "                if step < self.shape[0]-1:\n",
    "                    if img_step != step+1:\n",
    "                        if hasattr(fill_data, 'compute'):\n",
    "                            fill = fill_data[step+1].compute().data\n",
    "                        else:\n",
    "                            fill = fill_data[step+1]\n",
    "                        if hasattr(field_data, 'compute'):\n",
    "                            field = field_data[step+1].compute().data\n",
    "                        else:\n",
    "                            field = field_data[step+1]\n",
    "                        img_step = step+1\n",
    "                    \n",
    "                    fill_temp[i] = self._warp_flow_step(fill, step, \n",
    "                                                        method=method, \n",
    "                                                        direction='forward', \n",
    "                                                        offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                   * struct_factor[i]\n",
    "                    field_temp[i] = self._warp_flow_step(field, step, \n",
    "                                                         method=method, \n",
    "                                                         direction='forward', \n",
    "                                                         offset=[wh_layer[2][i]-1,wh_layer[1][i]-1]) \\\n",
    "                                    * struct_factor[i]\n",
    "                    wh = fill_temp[i]<0\n",
    "                    field_temp[i][wh] = np.inf\n",
    "#           For same time step:\n",
    "            else:\n",
    "                if img_step != step:\n",
    "                    if hasattr(fill_data, 'compute'):\n",
    "                        fill = fill_data[step].compute().data\n",
    "                    else:\n",
    "                        fill = fill_data[step]\n",
    "                    if hasattr(field_data, 'compute'):\n",
    "                        field = field_data[step].compute().data\n",
    "                    else:\n",
    "                        field = field_data[step]\n",
    "                    img_step = step\n",
    "                    \n",
    "                if wh_layer[1][i]==1 and wh_layer[2][i]==1:\n",
    "                    fill_temp[i] = fill * struct_factor[i]\n",
    "                    field_temp[i] = field * struct_factor[i]\n",
    "                else:\n",
    "                    loc = (slice(1 if wh_layer[2][i]==0 else 0, -1 if wh_layer[2][i]==2 else None),\n",
    "                           slice(1 if wh_layer[1][i]==0 else 0, -1 if wh_layer[1][i]==2 else None))\n",
    "                    fill_temp[i, loc[0], loc[1]] = fill[loc] * struct_factor[i]\n",
    "                    field_temp[i, loc[0], loc[1]] = field[loc] * struct_factor[i]\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        wh_fill_equal = fill_temp==fill_data[step]\n",
    "        fill_temp = np.maximum(field_temp, 0)\n",
    "        \n",
    "        field_temp[wh_fill_equal] = np.inf\n",
    "        field_temp[np.logical_not(np.isfinite(field_temp))] = np.inf\n",
    "        \n",
    "        inds = np.maximum(np.minimum(np.argmin(field_temp, 0), n_structure), 0)\n",
    "        out_field[step] = np.take_along_axis(field_temp, np.expand_dims(inds, 0), 0).squeeze()\n",
    "        out_fill[step] = np.take_along_axis(fill_temp, np.expand_dims(inds, 0), 0).squeeze()\n",
    "        \n",
    "    return out_field, out_fill\n",
    "\n",
    "flow._get_neighbour_fill_field = _get_neighbour_fill_field.__get__(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed(self, field, markers, mask=None, \n",
    "              structure=ndi.generate_binary_structure(3,1), \n",
    "              max_iter=100):\n",
    "    \n",
    "    assert structure.shape == (3,3,3), \"Structure input must be a 3x3x3 array\"\n",
    "    n_structure = np.count_nonzero(structure)\n",
    "    wh_layer = np.nonzero(structure)\n",
    "    assert field.shape == self.shape, \"Data input must have the same shape as the Flow object\"\n",
    "    assert markers.shape == self.shape\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.zeros(field.shape, dtype='bool')\n",
    "    else:\n",
    "        assert mask.shape == self.shape\n",
    "    if hasattr(mask, 'compute'):\n",
    "        mask = mask.compute().data\n",
    "    if isinstance(mask, ma.core.MaskedArray):\n",
    "        mask = mask.filled(fill_value=True)\n",
    "    mask = mask.astype('bool')\n",
    "    \n",
    "    if hasattr(markers, 'compute'):\n",
    "        markers = markers.compute().data\n",
    "    if isinstance(markers, ma.core.MaskedArray):\n",
    "        markers = markers.filled(fill_value=False)\n",
    "    \n",
    "    if isinstance(field, ma.core.MaskedArray):\n",
    "        field = field.filled(fill_value=np.nanmax(field))\n",
    "    wh = np.isnan(field)\n",
    "    if np.any(wh):\n",
    "        field[wh] = np.nanmax(field)\n",
    "        mask[wh] = True\n",
    "        markers[wh] = False\n",
    "    \n",
    "    if field.size<np.iinfo(np.int16).max:\n",
    "        uint_dtype = np.uint16\n",
    "        int_dtype = np.int16\n",
    "    elif field.size<np.iinfo(np.int32).max:\n",
    "        uint_dtype = np.uint32\n",
    "        int_dtype = np.int32\n",
    "    else:\n",
    "        uint_dtype = np.uint64\n",
    "        int_dtype = np.int64\n",
    "    \n",
    "    inds = np.arange(field.size, dtype=int_dtype).reshape(field.shape)\n",
    "    \n",
    "    print(\"Calculating nearest neighbours\") \n",
    "    inds_neighbour = self.arg_convolve(inds, field, func='argmin',\n",
    "                                       structure=structure, \n",
    "                                       method='nearest',\n",
    "                                       dtype=uint_dtype)\n",
    "    \n",
    "    mask[inds_neighbour>=field.size] = True\n",
    "    \n",
    "    inds_neighbour[inds_neighbour>=field.size] = 0\n",
    "    \n",
    "    fill_markers = markers.astype(int_dtype)\n",
    "    \n",
    "    fill_markers[mask] = -1\n",
    "    \n",
    "    wh_local_min = np.logical_and(inds_neighbour==inds, fill_markers==0)\n",
    "    \n",
    "    wh_markers = np.logical_or(wh_local_min, fill_markers!=0)\n",
    "    wh_to_fill = np.logical_not(wh_markers.copy())\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        inds_neighbour[wh_to_fill] = inds_neighbour.ravel()[inds_neighbour[wh_to_fill].ravel()]\n",
    "        # Check if any pixels have looped back to their original location\n",
    "        wh_loop = np.logical_and(wh_to_fill, inds_neighbour==inds)\n",
    "        if np.any(wh_loop):\n",
    "            wh_to_fill[wh_loop] = False\n",
    "            wh_local_min[wh_loop] = True\n",
    "            wh_markers[wh_loop] = True\n",
    "\n",
    "        # Now check if any have met a convergence location\n",
    "        wh_converge = wh_markers.ravel()[inds_neighbour[wh_to_fill]].ravel()\n",
    "        if np.any(wh_converge):\n",
    "            wh_to_fill[wh_to_fill] = np.logical_not(wh_converge)\n",
    "\n",
    "        \n",
    "        if not np.any(wh_to_fill):\n",
    "            print(\">\"*i, \"Pixels converged:\", np.sum(np.logical_not(wh_to_fill)))\n",
    "            break\n",
    "        print(\">\"*i, \"Pixels converged:\", np.sum(np.logical_not(wh_to_fill)), end='\\r')\n",
    "    \n",
    "    print(\"Filling basins\")\n",
    "    max_markers = np.nanmax(markers)\n",
    "    temp_markers = ndi.label(wh_local_min)[0][wh_local_min]+max_markers\n",
    "    fill_markers = fill_markers.astype(int_dtype)\n",
    "    fill_markers[wh_local_min] = temp_markers\n",
    "    fill = fill_markers.copy()\n",
    "    wh = fill==0\n",
    "    fill[wh] = fill.ravel()[inds_neighbour[wh].ravel()]\n",
    "    wh = fill==0\n",
    "    \n",
    "    if np.any(wh):\n",
    "        print(\"Some pixels not filled, adding\")\n",
    "        fill[wh] = ndi.label(wh)[0][wh]+np.nanmax(fill)\n",
    "    \n",
    "    fill = np.maximum(fill, 0)\n",
    "    \n",
    "    print(\"Joining labels\")\n",
    "    print(\"Max label:\", np.nanmax(fill))\n",
    "    print(\"max_markers:\", max_markers.astype(int))\n",
    "    \n",
    "    new_struct = structure.copy()\n",
    "    new_struct[1,1,1] = 0\n",
    "    \n",
    "    for iter in range(1, max_iter+1):\n",
    "        if fill.max() <= max_markers:\n",
    "            break\n",
    "        print('Joining labels, iteration:', iter, end='\\r')\n",
    "        field_neighbour, fill_neighbour = self._get_neighbour_fill_field(field, fill, structure=structure)\n",
    "        \n",
    "        field_neighbour = np.fmax(field_neighbour, field)\n",
    "        field_neighbour[fill_neighbour==fill] = np.nan\n",
    "        \n",
    "        return fill, field_edge, fill_edge\n",
    "        \n",
    "#       Bin the locations of all the fill values to iterate over\n",
    "        region_bins = np.nancumsum(np.bincount(fill.ravel()))\n",
    "        region_inds = np.argsort(fill.ravel())\n",
    "\n",
    "        region_map = {}\n",
    "\n",
    "        for label in range(max_markers+1, region_bins.size):\n",
    "            if region_bins[label]>region_bins[label-1]:\n",
    "                wh = region_inds[region_bins[label-1]:region_bins[label]]\n",
    "                if np.any(np.isfinite(field_neighbour.ravel()[wh])):\n",
    "                    region_map[label] = fill_neighbour.ravel()[wh][np.nanargmin(field_neighbour.ravel()[wh])]\n",
    "                    if region_map[label] == label:\n",
    "                        region_map[label] = 0\n",
    "                else:\n",
    "                    region_map[label] = 0\n",
    "\n",
    "        for k in region_map:\n",
    "            for i in range(100):\n",
    "                if region_map[k] <= max_markers:\n",
    "                    break\n",
    "                if region_map[region_map[k]] == k:\n",
    "                    if k > region_map[k]:\n",
    "                        break\n",
    "                    else:\n",
    "                        region_map[k] = k\n",
    "                        break\n",
    "                else:\n",
    "                    region_map[k] = region_map[region_map[k]]\n",
    "\n",
    "        for label in region_map:\n",
    "            if region_map[label] != label:\n",
    "                if region_bins[label]>region_bins[label-1]:\n",
    "                    fill.ravel()[region_inds[region_bins[label-1]:region_bins[label]]] = region_map[label]\n",
    "        \n",
    "    return fill\n",
    "\n",
    "flow.watershed = watershed.__get__(flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill, field_neighbour, fill_neighbour = flow.watershed(edges, markers, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(field_neighbour[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ma.array(fill_neighbour[24], mask=fill_neighbour[24]==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ma.array(fill[24], mask=fill[24]==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdb.runcall(flow._get_neighbour_fill_field, edges, fill, ndi.generate_binary_structure(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fill_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_markers=1\n",
    "\n",
    "region_bins = np.nancumsum(np.bincount(fill.ravel()))\n",
    "region_inds = np.argsort(fill.ravel())\n",
    "\n",
    "region_map = {}\n",
    "\n",
    "for label in range(max_markers+1, region_bins.size):\n",
    "    if region_bins[label]>region_bins[label-1]:\n",
    "        wh = region_inds[region_bins[label-1]:region_bins[label]]\n",
    "        if np.any(np.isfinite(field_neighbour.ravel()[wh])):\n",
    "            region_map[label] = fill_neighbour.ravel()[wh][np.nanargmin(field_neighbour.ravel()[wh])]\n",
    "            if region_map[label] == label:\n",
    "                region_map[label] = 0\n",
    "        else:\n",
    "            region_map[label] = 0\n",
    "\n",
    "for k in region_map:\n",
    "    for i in range(100):\n",
    "        if region_map[k] <= max_markers:\n",
    "            break\n",
    "        if region_map[region_map[k]] == k:\n",
    "            if k > region_map[k]:\n",
    "                break\n",
    "            else:\n",
    "                region_map[k] = k\n",
    "                break\n",
    "        else:\n",
    "            region_map[k] = region_map[region_map[k]]\n",
    "\n",
    "np.any(np.asarray(region_map.values()) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.array(list(region_map.values())) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = flow.watershed(edges, markers, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After joining labels -- only something is going wrong :/\n",
    "for i in range(0,33,5):\n",
    "    plt.figure(dpi=150, figsize=(8,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(ma.array(test[i], mask=test[i]==0))\n",
    "    plt.title(str(i))\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(ma.array(edges[i], mask=edges[i]==0))\n",
    "    plt.colorbar()    \n",
    "    plt.contour(test[i], [0.5], colors=['red'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prior to joining labels\n",
    "for i in range(0,33,5):\n",
    "    plt.figure(dpi=150, figsize=(8,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(ma.array(test[i], mask=test[i]==0))\n",
    "    plt.title(str(i))\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(edges[i])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = flow.sobel(np.maximum(np.minimum(wvd,-5),-15), direction='uphill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = wvd_diff>=0.5\n",
    "mask = (wvd.data < -15).compute()\n",
    "\n",
    "wh = edges > 0\n",
    "markers[wh] = 0\n",
    "mask[wh] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take_along_axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = np.random.rand(3,3,3)\n",
    "array_2 = np.random.rand(3,3,3)\n",
    "axis=1\n",
    "np.take_along_axis(array_2, np.expand_dims(np.argmax(array_1, axis), axis), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
